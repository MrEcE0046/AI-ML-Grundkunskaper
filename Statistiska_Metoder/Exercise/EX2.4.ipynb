{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of parts (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method.\n",
    "\n",
    "Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) \n",
    "The sample size $n$ is extremely large, and the number of predictors $p$ is small.\n",
    "\n",
    "Litet $p$ innebär att du har relativt få prediktorer alltså (egenskaper eller varibler) för att förklara variationen i din data. \n",
    "I denna situation kan du använda enklare modeller som linjär regrission eftersom det finns färre parametrar att uppskatta och risken för overfitting minskar. \n",
    "\n",
    "Stort $n$ innebär att di har en enorm mängd datapunkter. När $n$ är stort, säkerställer den stora urvalsstorleken att uppskattningarna av modellens parametrar blir mer stabila och exakta, vilket minskar osäkerheten i uppskattningarna. \n",
    "\n",
    "Fördelar med stort $n$ och litet $p$:\n",
    "\n",
    "* Stabila och pålitliga uppskattningar:\n",
    "Med ett stort $n$ kan du förvänta dig mycket precisa parametriska uppskattningar för din modell. Även om din modell är enkel kan du få mycket pålitliga och statistiskt signifikanta resultat pga den stora mängden data.\n",
    "\n",
    "* Minskad risk för overfittnig:\n",
    "Med ett litet antal prediktorer är risken för overfitting (där modellen memorerar datan istället för att generalisera) mindre, särskilt när urvalsstorleken är stor. Overfitting är mer preblematiskt när du har ett litet urval i förhållande till antalet prediktorer, eftersom modellen då kan passa för mycket på den specifika datan. \n",
    "\n",
    "* Effektiv beräkning:\n",
    "Eftersom antalet prediktorer är litet, är det lättare att beräkna din modell, även om urvalsstorleken är stor. \n",
    "\n",
    "Sammanfattning:\n",
    "När $n$ är mycket stort och $p$ är litet är du i en fördelaktig situation för att bygga exakta, tolkbara och beräkningsmässigt effektiva modeller. Den stora mängden data gör att uppskattningarna av modellens parametrar blir pålitliga med en misnakd risk för overfitting, och den enkla modellen gör tolkningen enkel. Detta är en situatio där klassiska modeller som linjär regression ocfta fungerar bra och ger meningsfulla resultat. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) \n",
    "The number of predictors p is extremely large, and the number of observations n is small.\n",
    "\n",
    "När antalet prediktorer $p$ är mycket större än antalet observationer $n$, står man inför stora utmaningar i form av overfitting, insabilitet och osäkerhet i parameteruppskattningen. För att hantera dessa problem används teknik som regularisering, dimensionalitetsreduktion, korsvalidering och beyesiansk inferens för att bygga mer robusta och generaliserbara modeller. I dessa sitioationer är det avgörande att noggrant välja och hantera modeller för att säkerställa åplitliga och meningsfulla resultat. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C)\n",
    "The relationship between the predictors and response is highly non-linear.\n",
    "\n",
    "När relationen mellan prediktorerna ocg responsen är icke linjär, innebär det att de traditionella linjära modellerna , som linjär regression eller logistisk regression, kanske inte kan fånga komplexiteten i sambandet mellan variablerna. Detta kan skapa problem föra att göra korrekta förutsägelser och dra meningsfulla slutsatser. \n",
    "\n",
    "* Vad innebär icke linjära relationer?\n",
    "Icke linjära relationer betyder attt förändringen i prediktorer inte resulterar i proportioneliga eller förutsägbara förändringar i responsen. T.EX om en förändring i en prediktor leder till en exponentiell ökning i responsen eller en förändring som inte är konstant över hela intervaööet för prediktorn, är icke linjär. \n",
    "\n",
    "Ett enkelt exempel är en kvadratisk relation (t.ex $y = x^2$), där effekten av $x$ inte är konstant utan beror på $x$s värde.\n",
    "\n",
    "Metoder för att hantera icke linjära relationer:\n",
    "* Polynomregression\n",
    "* Icke linjära regressionsmodeller\n",
    "* Trädmodeller\n",
    "* Kärnmetoder\n",
    "* Neurala nätverk\n",
    "\n",
    "Sammanfattning:\n",
    "\n",
    "När relationen mellan prediktorer och respons är starkt icke linjär, kan det var svårt att få bra resultat med linjära modeller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "### D) \n",
    "The variance of the error terms, i.e. 2 = Var( ), is extremely high.\n",
    "\n",
    "När variansen hos feltermerna ϵ är hög, innebär det att det finns stor variation eller osäkerhet i hur de faktiska observationerna avviker från de förväntade värderna som modellerna producerar. Detta kan ha konsekvenser för den statistiska modellen och förmågan att göra tillförlitliga förutsägelser. \n",
    "\n",
    "Vad innebär hög varians i feltermerna? \n",
    "* Feltermer eller residualer är skillnaderna mellan de observerade värderna och de värden som förutsägs av modeller. DVS $\\epsilon{i}= y{i}-\\hat{yi}$ där $yi$ är det faktiska värdet och $\\hat{yi}$ är det värde som modellen förutspår för observation $i$.\n",
    "* Om variansen hos feltermerna $\\sigma^2=Var(\\epsilon)$ är hög betyder det att modellen inte förklarar mycket av variationen i responsvariabeln. Detta innebär att förutsägelserna från modellen kan vara mycket osäkra eller spridda, vilket gör att modellen blir mindre tillförlitlig.\n",
    "\n",
    "Hög varians i feltermerna kan orsakas av flera faktorer:\n",
    "    * underfitting: Modellen fångar inte de verkliga mönstren i datan. \n",
    "    * Oberäkneliga eller okända faktorer: Om det finns andra faktorer som påverkar resultatet men som inte ingår i modellen, kan dessa faktorer skapa variation i feltermerna.\n",
    "    * Större osäkerhet i datan: Om det finns stora mätfel eller om data är mycket \"brusig\" dvs det finns mycket slumpmässigt brus i datan, kan det leda till hög varians i feltermerna. \n",
    "\n",
    "Konsekvenser av hög varians i feltermerna:\n",
    "* Mindre förtroende för modellen\n",
    "* Statistisk ineffektivitet\n",
    "* Ökad risk för overfitting\n",
    "\n",
    "### Summering\n",
    "När variansen i feltermerna är hög innebär det att modellen inte fångar variationen i datan på ett tillräkligt bra sätt, vilket kan leda till osäkra förutsägelser och dålig generalisering. För att hantera detta kan man överväga att:\n",
    "* Förbättra eller justera modellen\n",
    "* Använda regularisering för att miska risken för overfitting\n",
    "* Öka datamängden\n",
    "* Utföra datatransformationer för att minska extrem variation\n",
    "* Genomföra modellens diagnostik för att identifiera eventuella mönster i feltermerna\n",
    "\n",
    "\n",
    "Genom att noggrant hantera hög varians i feltermerna kan man förbättra modellens precision och tillförlitlighet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "---\n",
    "### Explain whether each scenario is a classification or regression problem, and indicate whether we are most interested in inference or prediction. Finally, provide n and p."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rekap på klassifiering och regressionsproblem\n",
    "\n",
    "Variabler kan delas in i två huvudtyper: kvantitativa och kvalitativa, även kända som kategoriska. Kvantitativa variabler har numeriska värden som en individs ålder, längd eller inkomst.\n",
    "Kvalitativa variabler är värden som tillhör en av flera olika klasser eller kategorier. T.ex en persons civilstånd, gift eller inte, eller produktvarumärke som köps, a, b eller c. \n",
    "Problemlösning med kvantitativ respons (värden) kallas ofta regressionsproblem medan problem med kvalitativ respons (ja/nej) ofta kallas klassifieringsproblem. Men denna distinktion är inte alltid så tydlig. Linjär regression används för kvantitiva svar, medan logistisk regression används för kvalitativa svar. \n",
    "\n",
    "Trots sitt namn är logistisk regression alltså en klassifieringsmetod, även om den kan ses som en regressionsmetod eftersom den uppskattar sannolikheten för olika klasser. \n",
    "\n",
    "Regression/kvantiativa = summor\n",
    "\n",
    "klassifiering/kvalitativa = ja/nej\n",
    "\n",
    "När vi väljer statistiska metoder baseras valet ofta på om svaret är kvantiativt eller kvaliativt (linjär regression för kvantiativa svar och logistisk regression för kvalitativa svar). Hur prediktorerna (ingående varibler) är definerade (kvantitativa eller kvalitativa) anses generellt var mindre viktigt. \n",
    "De flesta statistiska metoder kan användas oavsett typ av prediktor, så länge kvalitativa prediktorer kodas korrekt innan analysen.  \n",
    "\n",
    "Prediktion:\n",
    "\n",
    "I prediktionsproblem där vi har ingångar $X$ men inte lätt kan få utdata $Y$, används en funktion $\\hat{f}(X)$ för att förutsäga $Y$. Noggrannheten i denna prediktion beror på två typer av fel:\n",
    "* Reducerbart fel: Fel som kan minska genom att använda bättre metoder för att uppskatta funktionen $f$\n",
    "* Oreducerbart fel: Fel som inte kan minskas, eftersom det kommer från faktorer som inte kan mätas eller förutses, såsom oförutsägbar variation i data. \n",
    "\n",
    "Även en perfekt uppskattning av $f$, kommer det alltid finnas ett oreducerbart fel pga faktorer som feltermen $\\epsilon$, vilket gör att man inte kan göra en perfekt prediktion för $Y$. Målet är att minska det reducerbara felet, men det oreducerbara felet sätter en övre gräns för hur noggrant man kan förutsäga $Y$. \n",
    "\n",
    "Inom statistisk inlärning kan man fokusera på predition eller inferens, eller en kombinatition av båda, beroende på vad man har för mål.\n",
    "* Prediktion handlar om att förutsäga $Y$ baserat på $X$ utan att nödvändigtvis förstå exakt hur de är relaterade. Här används modeller för att göra så precisa förutsägelser som möjligt, även om de kan vara svårare att tolka.\n",
    "* Inferns handlar om att förstå sambanden mellan $Y$ och prediktorerna $X1,....,Xp$. Det kan innefatta frågor som: Vilka prediktorer påverkar $Y$ mest? Är sambandet linjärt eller mer komplext? Målet är att förstå relationerna och få insikt. \n",
    "\n",
    "Valet beror på målet: Linjära modeller är bra för inferens och tolkning men ger inte alltid de bästa prediktionerna, medans mer komplexa icke linjära modeller kan ge bättre prediktioner men är svårare att tolka. \n",
    "\n",
    "---\n",
    "\n",
    "-We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.\n",
    "\n",
    "* Problemet är ett regressionsproblem då alla varibler är i kvantiativa former. Alltså vi är ute efter ett numeriskt värde iform av en lön. \n",
    "* För att att kunna komma fram till vad som påverkar en chefslön mest måste man förstå alla variabler och dess inverkan med varandra, därför är detta em inferens. \n",
    "\n",
    "* $n$ är antalet företag, 500\n",
    "\n",
    "* $p$ är antalet prediktorer/variabler, (profit,number of employees, industri, salary), alltså 3 eller 4 om lönen ska räknas in. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.\n",
    "\n",
    "Svaret vi vill ha på detta problem är ett klassifierings problem, Vi kan använda oss av prediktion, $n$ = 20, $p$ = 14 variabler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interest in predicting the % change in the USD/Euro exchange rate in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.\n",
    "\n",
    "Kvantiativ form = regression, prediktion, $n$ = 52 (antal veckor 2012), $p$ = 4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### We now revisit the bias-variance decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why each of the five curves has the shape displayed in part.\n",
    "* Bias - sjunker med flexibilitet eftersom modellen blir mer sannolik att korrekt anpassa sig till data.\n",
    "* Varians - ökar med flexibilitet eftersom modellen blir mer svajig och följer data mer noggrant.\n",
    "* Training error - minskar med flexibilitet \n",
    "* Test error - minskar och sen ökar med flexibilitet, fel ökar för att modellen följer bruset av datan i träningsdatan, testdatan saknar samma brus. \n",
    "* oreducerbart fel - förblir konstant med metoden för att felen är inbakad i datan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "What are the advantages and disadvantages of a very flexible (versus a less flexible) approach for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexibl approach be preferred?\n",
    "\n",
    "Regression:\n",
    "Fördelar med flexibel regression:\n",
    "* Bättre passform till träningsdata. En flexibel modell kan passa träningsdatan bra vilket kan resultera i ett lågt träningsfel.\n",
    "* Modellen kan fånga komplexa och iocke linjära relationer mellan prediktorer och responsvariabeln vilket kan ge mer precisa resultat i vissa fall. \n",
    "* Förmågga att fånga komplexa mönster. En flexibel modell kan identifiera dolda eller komplexa samband som en enklare modell t.ex linjär regression inte kan fånga.\n",
    "* Minskad Bias. Eftersom modellen är mer flexibel, minskar risken för underfitting, och den kan bättre återspegla den verkliga fördelningen av data.\n",
    "\n",
    "Nackdelar med flexibel regretion:\n",
    "* Overfitting. En flexibel modell kan lätt anpassa sig för mycket till specifika detaljer eller brus i träningsdatan vilket kan leda till overfitting. Detta innebär att modellen fungerar bra på träningsdatan men generaliserar dåligt på ny data.\n",
    "* Högre varians. Det innebär att små förändringar i träningsdatan kan resultera i stora förändringar i modellens parametrar, vilket gör modellen känslig för variation i data och mindre stabil. \n",
    "* Svårtolkade modeller. Mer komplexa och flexibla modeller kan bli mycket svåra att tolka. \n",
    "* Beräkningskomplexitet. Ju mer flexibel modellen är destu mer resurser och längre träningstid kan den behöva. \n",
    "* Risk för att inte generalisera bra. Eftersom modellen är mycket anpassad till träningsdatan kan den ha svårt att generalisera till ny osedd data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
